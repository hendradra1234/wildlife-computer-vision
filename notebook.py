# -*- coding: utf-8 -*-
"""Computer_vision_Willdlife_Image_Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uTQHK416I3ZL-IdLNrUtCZKtMcgx_BKX

# Wildlife Computer Vision

Name: Hendra<br>
Email: hendradrakho@gmail.com<br>
Runtime: Google Colab Local Runtime<br>
CPU: AMD Ryzen 5 7640hs<br>
GPU: Nvidia RTX 4060 Mobile<br>
"""

pip install tensorflow

pip install kagglehub

mkdir -p /content

mkdir -p /content/drive

mkdir -p /content/drive/MyDrive

mkdir -p /content/drive/MyDrive/Dicoding-Machine-Learning

pwd

cd /content/drive/MyDrive/Dicoding-Machine-Learning/

pwd

mkdir -p bplm_wildlife_cv2025

cd  /content/drive/MyDrive/Dicoding-Machine-Learning/bplm_wildlife_cv2025

pwd

mkdir -p tfjs_model

mkdir -p tflite

mkdir -p saved_model

mkdir -p keras_model

!pip freeze > requirements.txt

"""## Configuration"""

import os
import cv2
import shutil
import kagglehub
import datetime
import numpy as np
import pandas as pd
import zipfile as zf
from PIL import Image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from sklearn.model_selection import train_test_split
from tqdm.notebook import tqdm as tq
from google.colab import files
import matplotlib.pyplot as plt
import seaborn as sns

import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)

os.environ["CUDA_VISIBLE_DEVICES"] = "0"

# Dataset Directory
dataset = 'alessiocorrado99/animals10'
destination = 'dataset/wildlife'

# Clean Dataset
split_path = 'dataset/wildlife_split'
train_path = os.path.join(split_path, 'train')
val_path = os.path.join(split_path, 'val')
test_path = os.path.join(split_path, 'test')
inference_test_dir = 'inference'
# Models
savename = 'wildlife_Model.tflite'
csv_log_save = 'wildlife_computer_vision(tf_lite)Log.csv'

model_save_keras_file = 'wildlife_computer_vision(tf_lite).keras'
models_save_tflite_file = 'wildlife_computer_vision.tflite'

# Training Config
models_save_tfjs = 'tfjs_model/'
models_save_tflite = os.path.join('tflite/', models_save_tflite_file)
models_save_tflite_label = os.path.join('tflite/', 'label.txt')
models_save_keras = os.path.join('keras_model/', model_save_keras_file)
models_save = 'saved_model/'

# Input Config
batchsize = 32
img_w = 224
img_h = 224
img_color = 3

"""# Data Preparation

## Load Dataset
"""

# Download latest version
path = kagglehub.dataset_download(dataset)

print("Path to dataset files:", path)

"""# Processing"""

# Spain to English Translate
translate = {
    "cane": "dog",
    "cavallo": "horse",
    "elefante": "elephant",
    "farfalla": "butterfly",
    "gallina": "chicken",
    "gatto": "cat",
    "mucca": "cow",
    "pecora": "sheep",
    "scoiattolo": "squirrel",
    "dog": "cane",
    "cavallo": "horse",
    "elephant" : "elefante",
    "butterfly": "farfalla",
    "chicken": "gallina",
    "cat": "gatto",
    "cow": "mucca",
    "ragno": "spider",
    "spider": "ragno",
    "squirrel": "scoiattolo"
}

def save_labels(datapath, labels):
    with open(datapath, 'w') as file:
        for label in labels:
            file.write(label)
            file.write('\n')

# Extract or Copy Dataset

def extract_or_copy(source_path, target_directory):
    try:
        # Ensure the target directory exists
        os.makedirs(target_directory, exist_ok=True)

        # Check if the source is a zip file
        if source_path.endswith('.zip'):
            with zf.ZipFile(source_path, 'r') as zip_file:
                zip_file.extractall(target_directory)
                print('Extraction completed successfully.')
        elif os.path.isdir(source_path):
            shutil.rmtree(target_directory)
            shutil.copytree(source_path, target_directory, dirs_exist_ok=True)
            print('Directory copied successfully.')
        else:
            print('Source is neither a .zip file nor a directory.')

    except FileNotFoundError:
        print(f"Source path '{source_path}' not found.")
    except PermissionError:
        print(f"Permission denied while accessing '{source_path}' or '{target_directory}'.")
    except Exception as e:
        print(f"An error occurred: {e}")
    finally:
        print('End the process.')

# Line chart to Plot Training accuracy and loss

def plot_training_model(histSave):
  acc = histSave.history['accuracy']
  epoch = range(len(acc))
  val_acc = histSave.history['val_accuracy']
  val_loss = histSave.history['val_loss']
  loss = histSave.history['loss']

  plt.figure(figsize = (15,5))
  plt.plot(epoch, acc, label='Training Accuracy')
  plt.plot(epoch, loss, label='Training Loss')
  plt.plot(epoch, val_acc, label='validation Acurracy')
  plt.plot(epoch, val_loss, label='validation Loss')
  plt.title('Plot Accuracy')
  plt.xlabel('Accuracy')
  plt.ylabel('Epoch')
  plt.legend()
  plt.show()

# Visualize Dataset Distribution

def pie_chart(classLen, MainDirList):
  size = classLen
  labels = MainDirlist

  plt.pie(
      size,
      labels=labels,
      autopct='%.1f%%',
      shadow=True,
      pctdistance=0.85,
      labeldistance=1.05,
      startangle=20,
      explode=[0 if 1 > 0 else 0.2 for i in range(len(size))]
  )
  plt.axis('equal')
  plt.show()

# EDA: Count number of images per category in each set

def count_images_in_directory(directory):
    category_count = {}
    for category in os.listdir(directory):
        category_path = os.path.join(directory, category)
        category_count[category] = len(os.listdir(category_path))
    return category_count

# Plot the distribution of images across categories for train, validation, and test sets

def plot_class_distribution(train_dist, test_dist, val_dist):
    plt.figure(figsize=(16, 5))

    plt.subplot(1, 3, 1)
    sns.barplot(x=list(train_dist.keys()), y=list(train_dist.values()), palette="Blues")
    plt.title("Training Set Distribution")
    plt.xlabel("Categories")
    plt.ylabel("Number of Images")

    plt.subplot(1, 3, 2)
    sns.barplot(x=list(val_dist.keys()), y=list(val_dist.values()), palette="Greens")
    plt.title("Validation Set Distribution")
    plt.xlabel("Categories")

    plt.subplot(1, 3, 3)
    sns.barplot(x=list(test_dist.keys()), y=list(test_dist.values()), palette="Reds")
    plt.title("Test Set Distribution")
    plt.xlabel("Categories")

    plt.tight_layout()
    plt.show()

"""## Data Preparation"""

extract_or_copy(os.path.join(path, 'raw-img'), destination)

os.listdir(destination)

MainDir = destination
original_dirlist = os.listdir(MainDir)

print(original_dirlist)
print('\n list data {}'.format(MainDir))

print('check translation:')

for i in original_dirlist:
  print(i, ':', translate.get(i))

classLen = []
dirlist = []

for i in original_dirlist:
    dir = os.path.join(MainDir, i)
    translate_dir = os.path.join(MainDir, translate.get(i))
    print('directory {}'.format(dir))
    print('translate directory')
    os.rename(dir, translate_dir)

    if os.path.isdir(dir):
      shutil.rmtree(dir)
    print('translate directory {}'.format(translate_dir))
    dirlist.append(translate_dir)
    dirQty = len(os.listdir(translate_dir))
    print('{} data'.format(dirQty))

    classLen.append(dirQty)

print('Total image data : {}'.format(sum(classLen)))

cnv_data = os.listdir(dirlist[0])
dme_data = os.listdir(dirlist[1])
drusen_data = os.listdir(dirlist[2])
normal_data = os.listdir(dirlist[3])

className = os.listdir(MainDir)
classQty = len(className)
MainDirlist = className
print('Class Name : {}'.format(className))
print('Class Qty  : {}'.format(classQty))

# Plotting image resolutions

resolutions = []

for className in dirlist:
    image_files = os.listdir(className)
    for img_name in image_files:
        img_path = os.path.join(className, img_name)
        img = cv2.imread(img_path)
        if img is not None:
            h, w, _ = img.shape
            resolutions.append((w, h))

resolutions = np.array(resolutions)

# Compute statistics

min_res = np.min(resolutions, axis=0)
median_res = np.median(resolutions, axis=0)
max_res = np.max(resolutions, axis=0)

print(f"Min Resolution: {min_res}")
print(f"Median Resolution: {median_res}")
print(f"Max Resolution: {max_res}")

# Plot resolution distribution

plt.figure(figsize=(8, 6))
plt.hist(resolutions[:, 0] * resolutions[:, 1], bins=30, color='blue', alpha=0.7)
plt.xlabel("Image Resolution (Width x Height Pixels)")
plt.ylabel("Frequency")
plt.title("Distribution of Image Resolutions")
plt.grid()
plt.show()

pie_chart(classLen, MainDirlist)

# Check Item inside Directory

if os.path.exists(MainDir):
    # List all files and directories in the dataset directory
    all_items = os.listdir(MainDir)

    # Iterate over all items and delete files
    for item in all_items:
        item_path = os.path.join(MainDir, item)
        if os.path.isfile(item_path):
            os.remove(item_path)
            print(f"Deleted file: {item_path}")

    # Print remaining items in the dataset directory
    remaining_items = os.listdir(MainDir)
    print(f"Remaining items in the dataset directory: {remaining_items}")
else:
    print(f"The directory {MainDir} does not exist.")

# Creating dictionary to store image path

img_dict = {}

path = MainDir
for i in os.listdir(path):
    img_dict[i] = os.listdir(os.path.join(path, i))

fig, axs = plt.subplots(len(img_dict.keys()), 5, figsize=(15, 15))

for i, class_name in enumerate(os.listdir(path)):
    images = np.random.choice(img_dict[class_name], 5, replace=False)

    for j, image_name in enumerate(images):
        img_path = os.path.join(path, class_name, image_name)
        img = Image.open(img_path)
        axs[i, j].imshow(img)
        axs[i, j].set(xlabel=class_name, xticks=[], yticks=[])


fig.tight_layout()

"""## Split Dataset"""

# Call the destination variable that holds the image dataset folder

file_name = []
labels = []
full_path = []
for path, subdirs, files in os.walk(destination):
    for name in files:
        full_path.append(os.path.join(path, name))
        labels.append(path.split('/')[-1])
        file_name.append(name)


df = pd.DataFrame({"path":full_path,'file_name':file_name,"labels":labels})
df.groupby(['labels']).size()

# train, val and test dataset split
X= df['path']
y= df['labels']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=123, stratify=y)

# Combine path and label to Dataframe

train = pd.DataFrame({'path':X_train, 'labels':y_train, 'set':'train'})

val_x, test_x, val_y, test_y = train_test_split(X_test, y_test, test_size=1/3, random_state=123)

val = pd.DataFrame({'path':val_x, 'labels':val_y, 'set':'val'})
test = pd.DataFrame({'path':test_x, 'labels':test_y, 'set':'test'})

print('train size', len(train))
print('val size', len(val))
print('test size', len(test))

# Merge Dataframe
df_all = pd.concat([train, val, test], ignore_index=True)

print(df_all.groupby(['set', 'labels']).size(), '\n')
print(df_all.sample(5))

# Split Image Dataset into Train, Val and Test Folder

if os.path.isdir(split_path):
  shutil.rmtree(split_path)

for index, row in tq(df_all.iterrows()):
    file_path = row['path']
    if os.path.exists(file_path) == False:
            file_path = os.path.join(destination, row['labels'], row['image'].split('.')[0])

    if os.path.exists(os.path.join(split_path, row['set'], row['labels'])) == False:
        os.makedirs(os.path.join(split_path, row['set'], row['labels']))

    destination_file_name = file_path.split('/')[-1]
    file_dest = os.path.join(split_path, row['set'], row['labels'], destination_file_name)

    if os.path.exists(file_dest) == False:
        shutil.copy2(file_path, file_dest)
if os.path.isdir(destination):
  shutil.rmtree(destination)

# Get image distribution for train, validation, and test sets

train_distribution = count_images_in_directory(train_path)
test_distribution = count_images_in_directory(test_path)
val_distribution = count_images_in_directory(val_path)

# Display class distribution plots

plot_class_distribution(train_distribution, test_distribution, val_distribution)

"""## Dataset Processing"""

#dataset Preprocessing

import tensorflow as tf
import numpy as np
from tensorflow import keras
from tensorflow.keras.preprocessing.image import ImageDataGenerator

datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
)

val_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

trainDatagen = datagen.flow_from_directory(
  train_path,
  batch_size = batchsize,
  target_size = (img_w, img_h),
  shuffle = True,
  interpolation = 'nearest',
  class_mode='sparse'
)


validationDatagen = val_datagen.flow_from_directory(
    val_path,
    batch_size = batchsize,
    target_size = (img_w, img_h),
    shuffle = True,
    interpolation = 'nearest',
    class_mode='sparse'
)

testDatagen = test_datagen.flow_from_directory(
    test_path,
    batch_size = batchsize,
    target_size = (img_w, img_h),
    shuffle = False,
    class_mode='sparse',
    interpolation = 'nearest'
)

classind = trainDatagen.class_indices
classmode = trainDatagen.class_mode
shape = trainDatagen.image_shape

print(classind)
print(classmode)
print(shape)

"""## Training"""

print(tf.config.list_physical_devices('GPU'))

# Adding base Model

from tensorflow import keras
from tensorflow.keras.layers import Dropout
from tensorflow.keras.models import Sequential
from keras.layers import BatchNormalization, Conv2D, MaxPool2D, Flatten, Dense, Input

base_model = tf.keras.applications.MobileNetV2(
      input_shape=(img_w, img_h, img_color),
      classifier_activation='softmax',
      include_top=False,
      weights='imagenet',
      classes=1000,
      alpha=1.0
    )

for layer in base_model.layers:
    layer.trainable = False

# Building a CNN model

model = tf.keras.models.Sequential([
    base_model,

    Conv2D(32, (3,3), activation='relu'),
    MaxPool2D(),
    Dropout(0.3),
    BatchNormalization(),

    Flatten(),
    Dense(128, activation='relu'),
    Dense(classQty, activation='softmax')
])

# Compile the model
model.compile(optimizer="adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"])

# Inspect parameters
total_params = model.count_params()
num_trainable_params = sum([w.shape.num_elements() for w in model.trainable_weights])

print(f"There are {total_params:} total parameters in this model.")
print(f"There are {num_trainable_params:} trainable parameters in this model.")

model.summary()

# Callback

import time
import datetime
import tensorboard as tb

log_dir = 'logs/fit/'+ datetime.datetime.now().strftime('%Y%m%d-%H%M%S')
file_writer = tf.summary.create_file_writer('/logs')
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = log_dir, histogram_freq = 1)

ACC_TRESHOLD = 0.97
patience = 5

class early_stopping(tf.keras.callbacks.Callback):
    def __init__(self, patience=0):
        super(early_stopping, self).__init__()
        self.patience = patience
        self.best_weights = None

    def on_train_begin(self, logs=None):
        self.wait = 0
        self.stopped_epoch = 0
        self.best = float('inf')

    def on_epoch_end(self, epoch, logs=None):
        current = logs.get('val_loss')
        if current is None:
            return

        if current < self.best:
            self.best = current
            self.wait = 0
            self.best_weights = self.model.get_weights()
        else:
            self.wait += 1
            if self.wait >= self.patience:
                self.stopped_epoch = epoch
                self.model.stop_training = True
                self.model.set_weights(self.best_weights)
                print(f"\nValidation loss not improving in 5 consecutive epochs, early stopping at epoch {self.stopped_epoch + 1}.")


class callback_acc_stopping(tf.keras.callbacks.Callback):
  def on_epoch_end(self,epoch,logs={}):
    if(logs.get('accuracy') >= ACC_TRESHOLD) and (logs.get('val_accuracy') >= ACC_TRESHOLD):
      print('\n akurasi mencapai {}&'.format(ACC_TRESHOLD*100))
      self.model.stop_training = True

lr_reduction = tf.keras.callbacks.ReduceLROnPlateau(
    monitor='val_loss',
    patience=3,
    verbose=1,
    factor=0.5,
    min_lr=0.00001
)

#Train Model

acc_stop = callback_acc_stopping()
saveLog = tf.keras.callbacks.CSVLogger(csv_log_save, separator=',', append=False)
early_stop = early_stopping(patience = patience)
tcc = time.perf_counter()

with tf.device('/device:GPU:0'):
  tcc = time.perf_counter()
  histSave =  model.fit(
      trainDatagen,
      epochs = 20,
      batch_size = batchsize,
      validation_data = validationDatagen,
      callbacks=[acc_stop, saveLog, tensorboard_callback, early_stop, lr_reduction],
      verbose=1
  )

toc = time.perf_counter()

print('Training Done')

"""## Evaluate Models"""

#Plotting Training

plot_training_model(histSave)

# Evaluate Models

true_classes = []
predicted_classes = []

for images, labels in testDatagen:
    predictions = model.predict(images, verbose=0)
    predicted_classes_batch = np.argmax(predictions, axis=1)

    if labels.ndim > 1 and labels.shape[1] > 1:
            labels = np.argmax(labels, axis=1)
    true_classes.extend(labels)
    predicted_classes.extend(predicted_classes_batch)

    if len(true_classes) >= testDatagen.samples:
        break

original_labels = [label for label, idx in sorted(trainDatagen.class_indices.items(), key=lambda item: item[1])]
original_labels

from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns

# Create confusion matrix
cm = confusion_matrix(true_classes, predicted_classes)

# Plot confusion matrix using Seaborn
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=original_labels, yticklabels=original_labels)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

# Evaluate on the training data

train_loss, train_accuracy = model.evaluate(trainDatagen, verbose=0)
print("Training Accuracy:", train_accuracy)

# Evaluate on the validation/test data

test_loss, test_accuracy = model.evaluate(validationDatagen, verbose=0)
print("Validation Accuracy:", test_accuracy)

# Evaluate on the validation/test data

test_loss, test_accuracy = model.evaluate(testDatagen, verbose=0)
print("Test Accuracy:", test_accuracy)

"""## Saving Models"""

#Save Tensorflow Models

model.save(models_save_keras)
model.export(models_save)

#Save tensorflow lite Model

converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

with open(models_save_tflite, "wb") as f:
    f.write(tflite_model)

save_labels(models_save_tflite_label, original_labels)

#Save Tensorflow JS Model

os.system(f"tensorflowjs_converter --input_format=tf_saved_model {models_save} {models_save_tfjs}")

print("Model training and saving complete!")

"""Inference Models"""

# Saved Models Inference

from tensorflow.keras.models import load_model
import cv2

trained_models = load_model(models_save_keras)
image_size = (img_w, img_h)


for filename in os.listdir(inference_test_dir):

    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):
        file_path = os.path.join(inference_test_dir, filename)

        image = cv2.imread(file_path)
        image = cv2.resize(image, image_size)

        img_array = tf.keras.preprocessing.image.img_to_array(image)
        img_array /= 255.0

        img_array = np.expand_dims(img_array, axis=0)

        prediction = trained_models.predict(img_array)
        predicted_class = np.argmax(prediction, axis=1)[0]

        predicted_label = original_labels[predicted_class]
        confidence = prediction[0][predicted_class]

        print(f"File: {filename} --> Predicted class: {predicted_label} with confidence: {confidence:.2f}")

        plt.imshow(image)
        plt.title(f"Prediction: {predicted_label}")
        plt.axis('off')
        plt.show()